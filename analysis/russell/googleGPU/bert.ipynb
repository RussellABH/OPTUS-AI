{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07903bba-6984-4b5c-b9f3-9013070f74d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bertopic in ./.local/lib/python3.10/site-packages (0.15.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from bertopic) (1.23.5)\n",
      "Requirement already satisfied: hdbscan>=0.8.29 in ./.local/lib/python3.10/site-packages (from bertopic) (0.8.33)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in ./.local/lib/python3.10/site-packages (from bertopic) (0.5.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /opt/conda/lib/python3.10/site-packages (from bertopic) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /opt/conda/lib/python3.10/site-packages (from bertopic) (1.3.1)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /opt/conda/lib/python3.10/site-packages (from bertopic) (4.66.1)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in ./.local/lib/python3.10/site-packages (from bertopic) (2.2.2)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /opt/conda/lib/python3.10/site-packages (from bertopic) (5.17.0)\n",
      "Requirement already satisfied: cython<3,>=0.27 in ./.local/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (0.29.36)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/conda/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly>=4.7.0->bertopic) (8.2.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from plotly>=4.7.0->bertopic) (23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in ./.local/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.35.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in ./.local/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (2.1.0)\n",
      "Requirement already satisfied: torchvision in ./.local/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.16.0)\n",
      "Requirement already satisfied: nltk in ./.local/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in ./.local/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in ./.local/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.17.3)\n",
      "Requirement already satisfied: numba>=0.51.2 in /opt/conda/lib/python3.10/site-packages (from umap-learn>=0.5.0->bertopic) (0.58.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in ./.local/lib/python3.10/site-packages (from umap-learn>=0.5.0->bertopic) (0.5.10)\n",
      "Requirement already satisfied: tbb>=2019.0 in ./.local/lib/python3.10/site-packages (from umap-learn>=0.5.0->bertopic) (2021.10.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.12.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2023.9.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.8.0)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.41.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (12.3.52)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in ./.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.4.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.1.7)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.local/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bertopic --user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b75a8994-78a8-4655-ac2e-9e5e2adf6e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cuda-python\n",
      "  Obtaining dependency information for cuda-python from https://files.pythonhosted.org/packages/03/80/b42e8fbae7fdaa21e4651e90cc21f69239047b7e6b957b988e0dfc3c9679/cuda_python-12.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading cuda_python-12.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Downloading cuda_python-12.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cuda-python\n",
      "Successfully installed cuda-python-12.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install cuda-python --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d6f9ef8-0a29-4f57-8c6a-7e29ce40c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f96120a-34b9-4c04-b21a-aa75be615d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data\n",
      "File 0 shape: (9406, 10)\n",
      "File 1 shape: (11135, 10)\n",
      "File 2 shape: (48437, 10)\n",
      "File 3 shape: (5215, 10)\n",
      "File 4 shape: (2906, 10)\n",
      "File 5 shape: (9030, 10)\n",
      "File 6 shape: (5132, 10)\n",
      "File 7 shape: (11630, 10)\n",
      "File 8 shape: (15932, 10)\n",
      "File 9 shape: (1430, 10)\n",
      "File 10 shape: (6797, 10)\n"
     ]
    }
   ],
   "source": [
    "# Since BERT uses sentence embeddings in it's process we want the stop words but the removed ones are useless\n",
    "# Testing on this one but it's really small so idk if the topics will be good\n",
    "print(f\"Reading in data\")\n",
    "dfs = []\n",
    "# pd.read_json(\"C:\\\\Users\\\\russe\\\\OneDrive\\\\Documents\\\\git\\\\Optus-data\\\\drugs-forum\\\\hydromorphone.json\", orient='records')\n",
    "dfs.append(pd.read_json(\"data/buprenorphine.json\", orient='records'))\n",
    "dfs.append(pd.read_json(\"data/codeine.json\", orient='records'))\n",
    "dfs.append(pd.read_json(\"data/heroin.json\", orient='records'))\n",
    "dfs.append(pd.read_json(\"data/hydrocodone.json\", orient='records'))\n",
    "dfs.append(pd.read_json(\"data/hydromorphone.json\", orient='records'))\n",
    "dfs.append(pd.read_json(\"data/methadone.json\", orient='records'))\n",
    "dfs.append(pd.read_json(\"data/morphine.json\", orient='records'))\n",
    "dfs.append(pd.read_json(\"data/opium-poppy.json\", orient='records'))\n",
    "dfs.append(pd.read_json(\"data/oxycodone.json\", orient='records'))\n",
    "dfs.append(pd.read_json(\"data/oxymorphone.json\", orient='records'))\n",
    "dfs.append(pd.read_json(\"data/tramadol.json\", orient='records'))\n",
    "# test = pd.DataFrame.from_dict(json.load(open(\"C:\\\\Users\\\\russe\\\\OneDrive\\\\Documents\\\\git\\\\Optus-data\\\\drugs-forum\\\\hydrocodone.json\", encoding='utf-8')))\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    print(f\"File {i} shape: {dfs[i].shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035295e8-8a30-470d-8a6d-26c85e337825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>post_content</th>\n",
       "      <th>rank</th>\n",
       "      <th>rep_points</th>\n",
       "      <th>messages</th>\n",
       "      <th>join_date</th>\n",
       "      <th>country_of_origin</th>\n",
       "      <th>date</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DanDone</td>\n",
       "      <td>Hi. I have a small codeine phosphate habit - I...</td>\n",
       "      <td>Newbie</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1458100800000</td>\n",
       "      <td>from U.K.</td>\n",
       "      <td>2023-10-18 04:00:00</td>\n",
       "      <td>Buprenorphine patch for codeine withdrawals</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheBigBadWolf</td>\n",
       "      <td>Hallo @Dan.\\nTrying to get yourself straight a...</td>\n",
       "      <td>Gold Member</td>\n",
       "      <td>16,967</td>\n",
       "      <td>9,563</td>\n",
       "      <td>1270958400000</td>\n",
       "      <td>from Germany</td>\n",
       "      <td>2023-10-18 04:00:00</td>\n",
       "      <td>Buprenorphine patch for codeine withdrawals</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DanDone</td>\n",
       "      <td>Thank you. I do have some pregabalin so will c...</td>\n",
       "      <td>Newbie</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1458100800000</td>\n",
       "      <td>from U.K.</td>\n",
       "      <td>2023-10-18 04:00:00</td>\n",
       "      <td>Buprenorphine patch for codeine withdrawals</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheBigBadWolf</td>\n",
       "      <td>That's a good decision. \\nAs I Had Said bupren...</td>\n",
       "      <td>Gold Member</td>\n",
       "      <td>16,967</td>\n",
       "      <td>9,563</td>\n",
       "      <td>1270958400000</td>\n",
       "      <td>from Germany</td>\n",
       "      <td>2023-10-18 04:00:00</td>\n",
       "      <td>Buprenorphine patch for codeine withdrawals</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Archangel Zadkiel</td>\n",
       "      <td>Thanks for the shout out @TheBigBadWolf long t...</td>\n",
       "      <td>Palladium Member</td>\n",
       "      <td>3,445</td>\n",
       "      <td>1,936</td>\n",
       "      <td>1333425600000</td>\n",
       "      <td>44\\ny/o\\nfrom Cincinnati, Ohio</td>\n",
       "      <td>2023-10-19 04:00:00</td>\n",
       "      <td>Buprenorphine patch for codeine withdrawals</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6792</th>\n",
       "      <td>paau</td>\n",
       "      <td>Ok so I took 200mg of tramadol last wednesday,...</td>\n",
       "      <td>Newbie</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>1186459200000</td>\n",
       "      <td>35\\ny/o\\nfrom U.S.A.</td>\n",
       "      <td>2007-10-09 04:00:00</td>\n",
       "      <td>\\nEffects of Tramadol when trying to come up o...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6793</th>\n",
       "      <td>trptamene</td>\n",
       "      <td>If the rolls are known to be good this WAS the...</td>\n",
       "      <td>Platinum Member &amp; Advisor</td>\n",
       "      <td>2,009</td>\n",
       "      <td>1,677</td>\n",
       "      <td>1121313600000</td>\n",
       "      <td>from U.S.A.</td>\n",
       "      <td>2007-10-09 04:00:00</td>\n",
       "      <td>\\nEffects of Tramadol when trying to come up o...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6794</th>\n",
       "      <td>paau</td>\n",
       "      <td>yeah sucks a bit really, I hasn't got much tra...</td>\n",
       "      <td>Newbie</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>1186459200000</td>\n",
       "      <td>35\\ny/o\\nfrom U.S.A.</td>\n",
       "      <td>2007-10-11 04:00:00</td>\n",
       "      <td>\\nEffects of Tramadol when trying to come up o...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6795</th>\n",
       "      <td>Nagognog2</td>\n",
       "      <td>Many people prescribed tramadol (Ultram) are n...</td>\n",
       "      <td>Iridium Member</td>\n",
       "      <td>1,936</td>\n",
       "      <td>6,713</td>\n",
       "      <td>1107234000000</td>\n",
       "      <td>None</td>\n",
       "      <td>2007-10-11 04:00:00</td>\n",
       "      <td>\\nEffects of Tramadol when trying to come up o...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6796</th>\n",
       "      <td>paau</td>\n",
       "      <td>thank you all for your help!</td>\n",
       "      <td>Newbie</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>1186459200000</td>\n",
       "      <td>35\\ny/o\\nfrom U.S.A.</td>\n",
       "      <td>2007-10-11 04:00:00</td>\n",
       "      <td>\\nEffects of Tramadol when trying to come up o...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127050 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               username                                       post_content  \\\n",
       "0               DanDone  Hi. I have a small codeine phosphate habit - I...   \n",
       "1         TheBigBadWolf  Hallo @Dan.\\nTrying to get yourself straight a...   \n",
       "2               DanDone  Thank you. I do have some pregabalin so will c...   \n",
       "3         TheBigBadWolf  That's a good decision. \\nAs I Had Said bupren...   \n",
       "4     Archangel Zadkiel  Thanks for the shout out @TheBigBadWolf long t...   \n",
       "...                 ...                                                ...   \n",
       "6792               paau  Ok so I took 200mg of tramadol last wednesday,...   \n",
       "6793          trptamene  If the rolls are known to be good this WAS the...   \n",
       "6794               paau  yeah sucks a bit really, I hasn't got much tra...   \n",
       "6795          Nagognog2  Many people prescribed tramadol (Ultram) are n...   \n",
       "6796               paau                       thank you all for your help!   \n",
       "\n",
       "                           rank rep_points messages      join_date  \\\n",
       "0                        Newbie         10        8  1458100800000   \n",
       "1                   Gold Member     16,967    9,563  1270958400000   \n",
       "2                        Newbie         10        8  1458100800000   \n",
       "3                   Gold Member     16,967    9,563  1270958400000   \n",
       "4              Palladium Member      3,445    1,936  1333425600000   \n",
       "...                         ...        ...      ...            ...   \n",
       "6792                     Newbie         14       40  1186459200000   \n",
       "6793  Platinum Member & Advisor      2,009    1,677  1121313600000   \n",
       "6794                     Newbie         14       40  1186459200000   \n",
       "6795             Iridium Member      1,936    6,713  1107234000000   \n",
       "6796                     Newbie         14       40  1186459200000   \n",
       "\n",
       "                   country_of_origin                date  \\\n",
       "0                          from U.K. 2023-10-18 04:00:00   \n",
       "1                       from Germany 2023-10-18 04:00:00   \n",
       "2                          from U.K. 2023-10-18 04:00:00   \n",
       "3                       from Germany 2023-10-18 04:00:00   \n",
       "4     44\\ny/o\\nfrom Cincinnati, Ohio 2023-10-19 04:00:00   \n",
       "...                              ...                 ...   \n",
       "6792            35\\ny/o\\nfrom U.S.A. 2007-10-09 04:00:00   \n",
       "6793                     from U.S.A. 2007-10-09 04:00:00   \n",
       "6794            35\\ny/o\\nfrom U.S.A. 2007-10-11 04:00:00   \n",
       "6795                            None 2007-10-11 04:00:00   \n",
       "6796            35\\ny/o\\nfrom U.S.A. 2007-10-11 04:00:00   \n",
       "\n",
       "                                             post_title post_type  \n",
       "0           Buprenorphine patch for codeine withdrawals  Question  \n",
       "1           Buprenorphine patch for codeine withdrawals  Question  \n",
       "2           Buprenorphine patch for codeine withdrawals  Question  \n",
       "3           Buprenorphine patch for codeine withdrawals  Question  \n",
       "4           Buprenorphine patch for codeine withdrawals  Question  \n",
       "...                                                 ...       ...  \n",
       "6792  \\nEffects of Tramadol when trying to come up o...            \n",
       "6793  \\nEffects of Tramadol when trying to come up o...            \n",
       "6794  \\nEffects of Tramadol when trying to come up o...            \n",
       "6795  \\nEffects of Tramadol when trying to come up o...            \n",
       "6796  \\nEffects of Tramadol when trying to come up o...            \n",
       "\n",
       "[127050 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Combining data\")\n",
    "df = pd.concat(dfs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6658f1e0-77c5-4b4f-b198-e7e9afdbba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing not-needed data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>post_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DanDone</td>\n",
       "      <td>Hi. I have a small codeine phosphate habit - I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheBigBadWolf</td>\n",
       "      <td>Hallo @Dan.\\nTrying to get yourself straight a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DanDone</td>\n",
       "      <td>Thank you. I do have some pregabalin so will c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheBigBadWolf</td>\n",
       "      <td>That's a good decision. \\nAs I Had Said bupren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Archangel Zadkiel</td>\n",
       "      <td>Thanks for the shout out @TheBigBadWolf long t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6792</th>\n",
       "      <td>paau</td>\n",
       "      <td>Ok so I took 200mg of tramadol last wednesday,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6793</th>\n",
       "      <td>trptamene</td>\n",
       "      <td>If the rolls are known to be good this WAS the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6794</th>\n",
       "      <td>paau</td>\n",
       "      <td>yeah sucks a bit really, I hasn't got much tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6795</th>\n",
       "      <td>Nagognog2</td>\n",
       "      <td>Many people prescribed tramadol (Ultram) are n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6796</th>\n",
       "      <td>paau</td>\n",
       "      <td>thank you all for your help!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127050 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               username                                       post_content\n",
       "0               DanDone  Hi. I have a small codeine phosphate habit - I...\n",
       "1         TheBigBadWolf  Hallo @Dan.\\nTrying to get yourself straight a...\n",
       "2               DanDone  Thank you. I do have some pregabalin so will c...\n",
       "3         TheBigBadWolf  That's a good decision. \\nAs I Had Said bupren...\n",
       "4     Archangel Zadkiel  Thanks for the shout out @TheBigBadWolf long t...\n",
       "...                 ...                                                ...\n",
       "6792               paau  Ok so I took 200mg of tramadol last wednesday,...\n",
       "6793          trptamene  If the rolls are known to be good this WAS the...\n",
       "6794               paau  yeah sucks a bit really, I hasn't got much tra...\n",
       "6795          Nagognog2  Many people prescribed tramadol (Ultram) are n...\n",
       "6796               paau                       thank you all for your help!\n",
       "\n",
       "[127050 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"removing not-needed data\")\n",
    "df = df.loc[:, ['username','post_content']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f39d3f-3dcd-4a7e-94ba-9d74ce5bf0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\", device='cuda') # fast but pretty accurate embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32dc8d5c-e424-4b03-961f-c0796f350180",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost_content\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fOut:\n\u001b[1;32m      4\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings-only1\u001b[39m\u001b[38;5;124m'\u001b[39m: embeddings},fOut)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:153\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target_device\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    156\u001b[0m length_sorted_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort([\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_length(sen) \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sentences])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 810 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    297\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 298\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    302\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver."
     ]
    }
   ],
   "source": [
    "embeddings = embedding_model.encode(df['post_content'].to_list(), show_progress_bar=True)\n",
    "\n",
    "with open(\"embeddings.pkl\", \"wb\") as fOut:\n",
    "    pickle.dump({'embeddings-only1': embeddings},fOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89cd8c68-cd6a-4538-8445-b24c5a5b0c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%dir` not found.\n"
     ]
    }
   ],
   "source": [
    "%dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cb1d76-2e1e-4335-a4f6-3cee25dce550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.13 (Local)",
   "language": "python",
   "name": "local-pytorch-1-13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
